## 2025-04-25

### What I changed

1. Improved docs
2. Added logging and graceful failing.
3. Automatically format with `black` before writing.
4. Add `diff_all.sh` for looking at diffs and updated VSCode settings
   {"diffEditor.ignoreTrimWhitespace": true,
   "diffEditor.wordWrap": "on"}.

### Why it matters

1. Did that using model suggestions. The suggested docs were almost always superior.
2. Logging and failing means we don't fail if one module fails. Was able to find that
   the `DocSigPatcher` needs work.
3. Keep diffs smaller.
4. Easier to view diffs.

### Measurements

### Notes after run on self

- Model fails to respond with properly formatted code on `ports.py` with the long
  module docstring.
  - Hypothesis 1: The docstring has a lot of special characters and
    markdown which muddy the model's thinking. NOT LIKELY BASED ON RESPONSE EXAMINATION.
  - Hypothesis 2: The current `DocSigPatcher` can't handle the unusual function
    definition in those classes.
- Current system prompt means updates on `prompt_builder.build_prompts` are no good.
  Interesting b/c the docs looked good (type hinting and numpy format), but the signature
  is incorrect and actually needs to be updated to reflect the current return values.
  I think the type hints for the libCST objects are off to.
- Need to be able to run on a single module and exclude certain subdirs if I want.
- Spacing can be slightly off when the model tries to respect the line length. For
  example, the next line after a >88 char line might start with a leading space.
  Interesting. Kind of annoying to edit.
- Would be interesting to examine the output at byte level. Sometimes when I copy-paste
  GPT code it includes extra bytes. Maybe invisible bytes?
- System gave correct type of the return value but didn't include it in the signature!
  This was on `src.application.services`.
- Seriously need a way to look at diffs. Even minor wording improvments are valuable.
  Need to be able to see them!
- Don't want output on already great docs. But the bar for great docs needs to be
  really high.
- Latency is pretty high (e.g. 11s on `domain`).
- Type hinting in Returns part of docs may be
  (`dict of str to FunctionEdit or ClassEdit`) instead of the more modern
  `dict[FunctionEdit | ClassEdit]`.
- Crap code -> crap doc output. This is anecdotal but it seems formatting is worse and
  the system respects line lengths less. Saw this on old
  `openai_client._get_api_key()` function.
- Would be nice to have a 'tidy up' tool which goes through and ensures the lines are
  set to the right length. Sometimes the new docs are great but a 90 char line means a
  lot of reformatting (e.g., move to new line, update trailing lines, etc.).
- I can add some logic to prevent sending a module for processing if it has no
  functions or classes (e.g. `gateways.schema_loader`).
- Want to run formatting immediately so diffs are smaller.
- Current system is removing examples. We need to be better at example generation.
- Type hinting on classes which reference themselves uses forward reference strings.
  Not exactly what we want.

### Failure to address

- Model fails to respond with properly formatted code on `ports.py` with the long
  module docstring.
  - Hypothesis 1: The docstring has a lot of special characters and
    markdown which muddy the model's thinking. EXAMINED RESPONSE: LOOKS FINE
  - Hypothesis 2: The current `DocSigPatcher` can't handle the protocol method
    definition in those classes. (e.g. `def foo(self, name): ...`)

### Open questions

- Need to be able to run this thing on one module.
- How to generate examples?
- What's a good codebase for me to learn on without overfitting? Need that.

### Next actions (tomorrow)
